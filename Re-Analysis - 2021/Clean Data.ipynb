{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import and Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.core.display import display, HTML\r\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from typing import Tuple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cols_to_use = ['SeqID', 'Date Of Stop', 'Time Of Stop', 'Agency', 'SubAgency',\r\n",
    "       'Description', 'Location', 'Latitude', 'Longitude', 'Accident', 'Belts',\r\n",
    "       'Personal Injury', 'Property Damage', 'Fatal', 'Commercial License',\r\n",
    "       'HAZMAT', 'Commercial Vehicle', 'Alcohol', 'Work Zone',\r\n",
    "       'Search Conducted', 'Search Disposition', 'Search Outcome',\r\n",
    "       'Search Reason', 'Search Reason For Stop', 'Search Type',\r\n",
    "       'Search Arrest Reason', 'State', 'VehicleType', 'Year', 'Make', 'Model',\r\n",
    "       'Color', 'Violation Type', 'Charge', 'Article',\r\n",
    "       'Contributed To Accident', 'Race', 'Gender', 'Arrest Type']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Traffic_Violations - Oct 6 2021.csv\",\r\n",
    "                nrows=25000,\r\n",
    "                usecols=cols_to_use)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assign Unique Stop ID "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def assign_stop_IDs(dataframe:pd.DataFrame) -> pd.DataFrame:\r\n",
    "    \"\"\"\r\n",
    "    Assigns a unique ID # for each stop.\r\n",
    "    Also deletes the 'SeqID' col.\r\n",
    "    \"\"\"\r\n",
    "    dataframe['merged_id_col'] = dataframe['SeqID'] + ' _ ' + dataframe['Date Of Stop'] + ' _ ' + dataframe['Time Of Stop']\r\n",
    "    \r\n",
    "    unique_stops = dataframe['merged_id_col'].unique()\r\n",
    "    \r\n",
    "    stop_ID_dict = {stop_info:ID for ID, stop_info in enumerate(unique_stops)}\r\n",
    "\r\n",
    "    dataframe.insert(loc=0,\r\n",
    "                     column='Stop ID',\r\n",
    "                     value=dataframe['merged_id_col'].map(stop_ID_dict))\r\n",
    "    \r\n",
    "    del dataframe['merged_id_col']\r\n",
    "    del dataframe['SeqID']\r\n",
    "    \r\n",
    "    dataframe.set_index('Stop ID', inplace=True)\r\n",
    "\r\n",
    "assign_stop_IDs(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert strings to boolean int (0, 1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_str_bool_cols(dataframe:pd.DataFrame) -> list:\r\n",
    "    \r\n",
    "    bool_cols = []\r\n",
    "    \r\n",
    "    str_bools_set = set(['Yes', 'No', np.nan])\r\n",
    "    for col in df:\r\n",
    "        if all([word in str_bools_set for word in df[col].unique()]):\r\n",
    "            bool_cols.append(col)\r\n",
    "            \r\n",
    "    return bool_cols\r\n",
    "\r\n",
    "def convert_str_bool_cols(dataframe:pd.DataFrame) -> pd.DataFrame:\r\n",
    "    \r\n",
    "    bool_cols = find_str_bool_cols(dataframe=dataframe)\r\n",
    "    \r\n",
    "    str_bool_mapping_dict = {'No':0, 'Yes':1}\r\n",
    "    \r\n",
    "    for col in bool_cols:\r\n",
    "        dataframe[col] = dataframe[col].map(str_bool_mapping_dict)\r\n",
    "    \r\n",
    "convert_str_bool_cols(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_cols(dataframe:pd.DataFrame) -> pd.DataFrame:\r\n",
    "    dataframe['Citation'] = (dataframe['Violation Type']=='Citation').astype(int)\r\n",
    "    dataframe['Warning'] = (dataframe['Violation Type']=='Warning').astype(int)    \r\n",
    "    \r\n",
    "    dataframe['Male'] = (dataframe['Gender']=='M').astype(int)\r\n",
    "    dataframe['Female'] = (dataframe['Gender']=='F').astype(int)\r\n",
    "    \r\n",
    "    dataframe['Probable Cause'] = (dataframe['Search Reason']=='Probable Cause').astype(int)\r\n",
    "    dataframe['Arrest'] = (dataframe['Search Outcome']=='Arrest').astype(int)\r\n",
    "    \r\n",
    "    dataframe['DateTime'] = pd.to_datetime(df['Date Of Stop'] + ' ' + df['Time Of Stop'])\r\n",
    "    del dataframe['Date Of Stop'], dataframe['Time Of Stop']\r\n",
    "\r\n",
    "create_cols(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Speed Columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_speed_and_limit_from_split_str(split_description:list) -> Tuple[float, float]:\r\n",
    "    \"\"\"\r\n",
    "    :INPUT:\r\n",
    "    'split_description'=df['Description].str.split() element\r\n",
    "\r\n",
    "    :OUTPUT:\r\n",
    "    [posted_limit, speed_over_limit]\r\n",
    "    speed_over_limit is often not recorded, so this sometimes returns [posted_limit, np.nan]\r\n",
    "    \"\"\"\r\n",
    "    speeds_from_description = tuple([int(word) for word in split_description if word.isdigit()])\r\n",
    "    \r\n",
    "    if len(speeds_from_description)==2: # if posted limit and driver's speed are both recorded\r\n",
    "        return sorted(speeds_from_description)\r\n",
    "    elif len(speeds_from_description)==1: # if only posted limit is recorded\r\n",
    "        return (speeds_from_description[0], np.nan)\r\n",
    "    elif len(speeds_from_description)==0: # if neither posted limit nor driver speed were recorded\r\n",
    "        return (np.nan, np.nan)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_speed_columns(dataframe:pd.DataFrame) -> pd.DataFrame:\r\n",
    "    limit_and_speed_cols = dataframe['Description'].str.split().apply(get_speed_and_limit_from_split_str).apply(pd.Series)\r\n",
    "    \r\n",
    "    limit_and_speed_cols.rename(columns={0:'Speed Limit',\r\n",
    "                                         1:'Recorded Speed'}, inplace=True)\r\n",
    "    \r\n",
    "    return pd.concat([dataframe, limit_and_speed_cols], axis=1)\r\n",
    "    \r\n",
    "df = create_speed_columns(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create cols for \"ID Corresponds to (accident, search, etc.)\r\n",
    "Where it equals 1 for all rows with that stop ID if any row with that stop ID have (accident, search, etc.).\r\n",
    "\r\n",
    "Honestly not sure if this is necessary (didn't see a need for it in my sample) but better to be safe..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def fill_sparse_fields(dataframe:pd.DataFrame, cols:list) -> pd.DataFrame:\r\n",
    "        \r\n",
    "    for col in cols:\r\n",
    "        stop_ID_equals_1_somewhere = set(dataframe.index[dataframe[col]==1])\r\n",
    "        stop_ID_doesnt_equal_1_anywhere = set(dataframe.index) - stop_ID_equals_1_somewhere\r\n",
    "        \r\n",
    "        filled_col_name = f'{col} - Sparse Filled'\r\n",
    "        \r\n",
    "        dataframe[filled_col_name] = np.nan\r\n",
    "        \r\n",
    "        dataframe.loc[stop_ID_equals_1_somewhere, filled_col_name] = 1\r\n",
    "        dataframe.loc[stop_ID_doesnt_equal_1_anywhere, filled_col_name] = dataframe.loc[stop_ID_doesnt_equal_1_anywhere, col] # assign old value to stops which don't have any rows == 1\r\n",
    "\r\n",
    "\r\n",
    "potentially_sparse_cols = [col for col in df if set(df[col].unique().tolist())=={0,1}]\r\n",
    "\r\n",
    "\r\n",
    "fill_sparse_fields(dataframe=df, \r\n",
    "                   cols=potentially_sparse_cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_first_row_of_each_stop(dataframe:pd.DataFrame) -> pd.DataFrame:\r\n",
    "    return dataframe[~dataframe.index.duplicated(keep='first')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.to_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Modified Dataset - 2021.csv\")\r\n",
    "\r\n",
    "get_first_row_of_each_stop(df).to_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Modified Dataset - 2021 - One Row per Stop.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "interpreter": {
   "hash": "7fe840cb6503e6e121073d91483f2f283b736cdf5bfd63e897a03cab3c1751ec"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}