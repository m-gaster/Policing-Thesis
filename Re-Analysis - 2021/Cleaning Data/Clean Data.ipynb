{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = ['SeqID', 'Date Of Stop', 'Time Of Stop', 'Agency', 'SubAgency',\n",
    "       'Description', 'Location', 'Latitude', 'Longitude', 'Accident', 'Belts',\n",
    "       'Personal Injury', 'Property Damage', 'Fatal', 'Commercial License',\n",
    "       'HAZMAT', 'Commercial Vehicle', 'Alcohol', 'Work Zone',\n",
    "       'Search Conducted', 'Search Disposition', 'Search Outcome',\n",
    "       'Search Reason', 'Search Reason For Stop', 'Search Type',\n",
    "       'Search Arrest Reason', 'State', 'VehicleType', 'Year', 'Make', 'Model',\n",
    "       'Color', 'Violation Type', 'Charge', 'Article',\n",
    "       'Contributed To Accident', 'Race', 'Gender', 'Arrest Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikha\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3172: DtypeWarning: Columns (19,20,21,22,23,24,25,34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Traffic_Violations - Oct 6 2021.csv\",\n",
    "                # nrows=25000,\n",
    "                usecols=cols_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Unique Stop ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_stop_IDs(dataframe:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assigns a unique ID # for each stop.\n",
    "    Also deletes the 'SeqID' col.\n",
    "    \"\"\"\n",
    "    dataframe['merged_id_col'] = dataframe['SeqID'] + ' _ ' + dataframe['Date Of Stop'] + ' _ ' + dataframe['Time Of Stop']\n",
    "    \n",
    "    unique_stops = dataframe['merged_id_col'].unique()\n",
    "    \n",
    "    stop_ID_dict = {stop_info:ID for ID, stop_info in enumerate(unique_stops)}\n",
    "\n",
    "    dataframe.insert(loc=0,\n",
    "                     column='Stop ID',\n",
    "                     value=dataframe['merged_id_col'].map(stop_ID_dict))\n",
    "    \n",
    "    del dataframe['merged_id_col']\n",
    "    del dataframe['SeqID']\n",
    "    \n",
    "    dataframe.set_index('Stop ID', inplace=True)\n",
    "\n",
    "assign_stop_IDs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to boolean int (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_str_bool_cols(dataframe:pd.DataFrame) -> list:\n",
    "    \n",
    "    bool_cols = []\n",
    "    \n",
    "    str_bools_set = set(['Yes', 'No', np.nan])\n",
    "    for col in df:\n",
    "        if all([word in str_bools_set for word in df[col].unique()]):\n",
    "            bool_cols.append(col)\n",
    "            \n",
    "    return bool_cols\n",
    "\n",
    "def convert_str_bool_cols(dataframe:pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    bool_cols = find_str_bool_cols(dataframe=dataframe)\n",
    "    \n",
    "    str_bool_mapping_dict = {'No':0, 'Yes':1}\n",
    "    \n",
    "    for col in bool_cols:\n",
    "        dataframe[col] = dataframe[col].map(str_bool_mapping_dict)\n",
    "    \n",
    "convert_str_bool_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cols(dataframe:pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe['Citation'] = (dataframe['Violation Type']=='Citation').astype(int)\n",
    "    dataframe['Warning'] = (dataframe['Violation Type']=='Warning').astype(int)    \n",
    "    \n",
    "    dataframe['Male'] = (dataframe['Gender']=='M').astype(int)\n",
    "    dataframe['Female'] = (dataframe['Gender']=='F').astype(int)\n",
    "    \n",
    "    dataframe['Probable Cause'] = (dataframe['Search Reason']=='Probable Cause').astype(int)\n",
    "    dataframe['Arrest'] = (dataframe['Search Outcome']=='Arrest').astype(int)\n",
    "    \n",
    "    dataframe['DateTime'] = pd.to_datetime(df['Date Of Stop'] + ' ' + df['Time Of Stop'])\n",
    "    del dataframe['Date Of Stop'], dataframe['Time Of Stop']\n",
    "\n",
    "create_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speed_and_limit_from_split_str(split_description:list) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    :INPUT:\n",
    "    'split_description'=df['Description].str.split() element\n",
    "\n",
    "    :OUTPUT:\n",
    "    [posted_limit, speed_over_limit]\n",
    "    speed_over_limit is often not recorded, so this sometimes returns [posted_limit, np.nan]\n",
    "    \"\"\"\n",
    "    speeds_from_description = tuple([int(word) for word in split_description if word.isdigit()])\n",
    "    \n",
    "    if len(speeds_from_description)==2: # if posted limit and driver's speed are both recorded\n",
    "        return sorted(speeds_from_description)\n",
    "    elif len(speeds_from_description)==1: # if only posted limit is recorded\n",
    "        return (speeds_from_description[0], np.nan)\n",
    "    elif len(speeds_from_description)==0: # if neither posted limit nor driver speed were recorded\n",
    "        return (np.nan, np.nan)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_speed_columns(dataframe:pd.DataFrame) -> pd.DataFrame:\n",
    "    limit_and_speed_cols = dataframe['Description'].fillna('').str.split().apply(get_speed_and_limit_from_split_str).apply(pd.Series)\n",
    "    \n",
    "    limit_and_speed_cols.rename(columns={0:'Speed Limit',\n",
    "                                         1:'Recorded Speed'}, inplace=True)\n",
    "    \n",
    "    return pd.concat([dataframe, limit_and_speed_cols], axis=1)\n",
    "    \n",
    "df = create_speed_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cols for \"ID Corresponds to (accident, search, etc.)\n",
    "Where it equals 1 for all rows with that stop ID if any row with that stop ID have (accident, search, etc.).\n",
    "\n",
    "Honestly not sure if this is necessary (didn't see a need for it in my sample) but better to be safe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_sparse_fields(dataframe:pd.DataFrame, cols:list) -> pd.DataFrame:\n",
    "        \n",
    "    for col in cols:\n",
    "        stop_ID_equals_1_somewhere = set(dataframe.index[dataframe[col]==1])\n",
    "        stop_ID_doesnt_equal_1_anywhere = set(dataframe.index) - stop_ID_equals_1_somewhere\n",
    "        \n",
    "        filled_col_name = f'{col} - Sparse Filled'\n",
    "        \n",
    "        dataframe[filled_col_name] = np.nan\n",
    "        \n",
    "        dataframe.loc[stop_ID_equals_1_somewhere, filled_col_name] = 1\n",
    "        dataframe.loc[stop_ID_doesnt_equal_1_anywhere, filled_col_name] = dataframe.loc[stop_ID_doesnt_equal_1_anywhere, col] # assign old value to stops which don't have any rows == 1\n",
    "\n",
    "\n",
    "potentially_sparse_cols = [col for col in df if set(df[col].unique().tolist())=={0,1}]\n",
    "\n",
    "sparse_cols = potentially_sparse_cols + ['Speed Limit', 'Recorded Speed']\n",
    "\n",
    "fill_sparse_fields(dataframe=df, \n",
    "                   cols=sparse_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_row_of_each_stop(dataframe:pd.DataFrame) -> pd.DataFrame:\n",
    "    return dataframe[~dataframe.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Modified Dataset - 2021.csv\")\n",
    "\n",
    "get_first_row_of_each_stop(df).to_csv(\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Modified Dataset - 2021 - One Row per Stop.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fe840cb6503e6e121073d91483f2f283b736cdf5bfd63e897a03cab3c1751ec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
