{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/My-Package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from myfunctions import clean_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=clean_path(r\"C:/Users/mikha/Dropbox/mikhael_misc/Projects/Policing Thesis/Modified Dataset - 2021.csv\"),\n",
    "                 index_col='Stop ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossTabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can one stop get multiple accident rows?\n",
    "\n",
    "Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Accident'].sum() != len(df[df['Accident']==1].index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstabs_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stops weighted by # tickets\n",
    "\n",
    "(Should find a better name for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstabs_dict['Stops weighted by # tickets'] = df['Race'].value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fnc for similar cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_crosstab_from_duplicate_IDs(dataframe:pd.DataFrame, col:str, col_val_to_filter, get_total_stops=False) -> pd.Series:\n",
    "    \n",
    "    if get_total_stops:\n",
    "        race_col_with_ID = dataframe['Race'].reset_index()\n",
    "    else:    \n",
    "        race_col_with_ID = dataframe[dataframe[col]==col_val_to_filter]['Race'].reset_index()\n",
    "    \n",
    "    grouped_race_col_with_ID = race_col_with_ID.groupby(by='Stop ID').agg(set)\n",
    "    \n",
    "    grouped_race_col_with_ID['Race'] = grouped_race_col_with_ID['Race'].apply(list).apply(lambda x: x[0])\n",
    "    \n",
    "    val_counts = grouped_race_col_with_ID.value_counts(normalize=True).sort_index()\n",
    "\n",
    "    val_counts.index = val_counts.index.get_level_values(0)\n",
    "    \n",
    "    return val_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bool_col in ['Accident',\n",
    "                 'Citation',\n",
    "                 'Warning',\n",
    "                 'Probable Cause',\n",
    "                 'Arrest',\n",
    "                 'Search Conducted']:\n",
    "    crosstabs_dict[bool_col] = get_race_crosstab_from_duplicate_IDs(dataframe=df,\n",
    "                                                                    col=bool_col,\n",
    "                                                                    col_val_to_filter=1)\n",
    "    \n",
    "crosstabs_dict['Stops'] = get_race_crosstab_from_duplicate_IDs(dataframe=df,\n",
    "                                                               col=None,\n",
    "                                                               col_val_to_filter=None,\n",
    "                                                               get_total_stops=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstabs_df = pd.DataFrame(crosstabs_dict).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stops weighted by # tickets</th>\n",
       "      <th>Accident</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Warning</th>\n",
       "      <th>Probable Cause</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Search Conducted</th>\n",
       "      <th>Stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASIAN</th>\n",
       "      <td>0.04612</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.048206</td>\n",
       "      <td>0.055763</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.054001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK</th>\n",
       "      <td>0.35148</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.310419</td>\n",
       "      <td>0.329566</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.383260</td>\n",
       "      <td>0.473538</td>\n",
       "      <td>0.319746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC</th>\n",
       "      <td>0.25780</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.266969</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.303965</td>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.226028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATIVE AMERICAN</th>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>0.05804</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>0.057933</td>\n",
       "      <td>0.075168</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.070307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE</th>\n",
       "      <td>0.28608</td>\n",
       "      <td>0.307851</td>\n",
       "      <td>0.315607</td>\n",
       "      <td>0.334577</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.222841</td>\n",
       "      <td>0.329245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Stops weighted by # tickets  Accident  Citation   Warning  \\\n",
       "ASIAN                                0.04612  0.045455  0.048206  0.055763   \n",
       "BLACK                                0.35148  0.285124  0.310419  0.329566   \n",
       "HISPANIC                             0.25780  0.322314  0.266969  0.204286   \n",
       "NATIVE AMERICAN                      0.00048  0.000000  0.000865  0.000640   \n",
       "OTHER                                0.05804  0.039256  0.057933  0.075168   \n",
       "WHITE                                0.28608  0.307851  0.315607  0.334577   \n",
       "\n",
       "                 Probable Cause    Arrest  Search Conducted     Stops  \n",
       "ASIAN                  0.026667  0.026432          0.030641  0.054001  \n",
       "BLACK                  0.620000  0.383260          0.473538  0.319746  \n",
       "HISPANIC               0.153333  0.303965          0.253482  0.226028  \n",
       "NATIVE AMERICAN        0.006667  0.004405          0.002786  0.000673  \n",
       "OTHER                  0.026667  0.022026          0.016713  0.070307  \n",
       "WHITE                  0.166667  0.259912          0.222841  0.329245  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstabs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Pop\n",
    "\n",
    "https://www.census.gov/quickfacts/montgomerycountymaryland\n",
    "\n",
    "\"Native Hawaiian and Other Pacific Islander alone\" --> \"OTHER\"\n",
    "\"Two or More Races\" --> \"OTHER\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "asian=.156\n",
    "black=.201\n",
    "native_american=.000\n",
    "hispanic=.201\n",
    "white=.429\n",
    "\n",
    "other = 1 - (asian + black + native_american + hispanic + white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_pop = pd.Series(data=[asian, black, hispanic, native_american, other, white],\n",
    "                   index=['ASIAN', 'BLACK', 'HISPANIC', 'NATIVE AMERICAN', 'OTHER', 'WHITE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstabs_df.insert(loc=0, \n",
    "                    column='MC Population',\n",
    "                    value=mc_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder Columns / Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstabs_df.rename(columns={'Stops weighted by # tickets': 'Stops X # Tickets',\n",
    "                             'Search Conducted':'Searches',\n",
    "                             'Probable Cause':'Prob. Cause',\n",
    "                             'Arrest':'Arrests', \n",
    "                             'Warning':'Warnings',\n",
    "                             'Accident':'Accidents',\n",
    "                             'Citation':'Citations', \n",
    "                             'MC Population':'MC Pop.'}, inplace=True)\n",
    "\n",
    "new_col_order = ['MC Pop.', 'Accidents', 'Stops', 'Stops X # Tickets', 'Citations', 'Warnings', 'Arrests', 'Searches', 'Prob. Cause']\n",
    "\n",
    "crosstabs_df = crosstabs_df[new_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MC Pop.</th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Stops</th>\n",
       "      <th>Stops X # Tickets</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Warnings</th>\n",
       "      <th>Arrests</th>\n",
       "      <th>Searches</th>\n",
       "      <th>Prob. Cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASIAN</th>\n",
       "      <td>0.156</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.054001</td>\n",
       "      <td>0.04612</td>\n",
       "      <td>0.048206</td>\n",
       "      <td>0.055763</td>\n",
       "      <td>0.026432</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.285124</td>\n",
       "      <td>0.319746</td>\n",
       "      <td>0.35148</td>\n",
       "      <td>0.310419</td>\n",
       "      <td>0.329566</td>\n",
       "      <td>0.383260</td>\n",
       "      <td>0.473538</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC</th>\n",
       "      <td>0.201</td>\n",
       "      <td>0.322314</td>\n",
       "      <td>0.226028</td>\n",
       "      <td>0.25780</td>\n",
       "      <td>0.266969</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.303965</td>\n",
       "      <td>0.253482</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATIVE AMERICAN</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>0.013</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.05804</td>\n",
       "      <td>0.057933</td>\n",
       "      <td>0.075168</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE</th>\n",
       "      <td>0.429</td>\n",
       "      <td>0.307851</td>\n",
       "      <td>0.329245</td>\n",
       "      <td>0.28608</td>\n",
       "      <td>0.315607</td>\n",
       "      <td>0.334577</td>\n",
       "      <td>0.259912</td>\n",
       "      <td>0.222841</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 MC Pop.  Accidents     Stops  Stops X # Tickets  Citations  \\\n",
       "ASIAN              0.156   0.045455  0.054001            0.04612   0.048206   \n",
       "BLACK              0.201   0.285124  0.319746            0.35148   0.310419   \n",
       "HISPANIC           0.201   0.322314  0.226028            0.25780   0.266969   \n",
       "NATIVE AMERICAN    0.000   0.000000  0.000673            0.00048   0.000865   \n",
       "OTHER              0.013   0.039256  0.070307            0.05804   0.057933   \n",
       "WHITE              0.429   0.307851  0.329245            0.28608   0.315607   \n",
       "\n",
       "                 Warnings   Arrests  Searches  Prob. Cause  \n",
       "ASIAN            0.055763  0.026432  0.030641     0.026667  \n",
       "BLACK            0.329566  0.383260  0.473538     0.620000  \n",
       "HISPANIC         0.204286  0.303965  0.253482     0.153333  \n",
       "NATIVE AMERICAN  0.000640  0.004405  0.002786     0.006667  \n",
       "OTHER            0.075168  0.022026  0.016713     0.026667  \n",
       "WHITE            0.334577  0.259912  0.222841     0.166667  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crosstabs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstabs_df.to_csv(r\"Crosstabs by Race.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fe840cb6503e6e121073d91483f2f283b736cdf5bfd63e897a03cab3c1751ec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
