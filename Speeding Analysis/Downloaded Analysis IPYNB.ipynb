{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:97% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:97% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True) #no scientific notation\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"Geo Modified Dataset - 80 cells - width==0.1 .csv\", index_col=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_set = {'ASIAN', 'BLACK', 'HISPANIC', 'NATIVE AMERICAN', 'OTHER', 'WHITE'}\n",
    "\n",
    "for race in race_set:\n",
    "    df[f\"INTERACTION: D_{race} X GEO: {race} Racial Composition\"] = df[f'{race} - (D_Race)'] * df[f'GEO: {race} Racial Composition']\n",
    "    \n",
    "    df[f\"INTERACTION: D_{race} X GEO: {race} Percent of Charges that were CHANGED\"] = df[f'{race} - (D_Race)'] * df[f'GEO: {race} Percent of Charges that were CHANGED']\n",
    "    \n",
    "    df[f\"INTERACTION: D_{race} X GEO: {race} Average Speed NOT in 9,14 MPH\"] = df[f'{race} - (D_Race)'] * df[f'GEO: {race} Average Speed NOT in 9,14 MPH']\n",
    "    \n",
    "    df[f\"INTERACTION: D_{race} X D_Male\"] = df[f'{race} - (D_Race)'] * df[\"Male\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi-Squared Test for Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_set = {'ASIAN', 'BLACK', 'HISPANIC', 'NATIVE AMERICAN', 'OTHER', 'WHITE'}\n",
    "speeding_bool_set = {\"Speed Altered\", 'Speed NOT Altered'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "altered = []\n",
    "not_altered = []\n",
    "\n",
    "\n",
    "for x in df['Speed Over Posted Limit']:\n",
    "    if x==9:\n",
    "        altered.append(1)\n",
    "        not_altered.append(0)\n",
    "    elif 10 <= x <= 14:\n",
    "        altered.append(0)\n",
    "        not_altered.append(1)\n",
    "    else:\n",
    "        altered.append(np.nan)\n",
    "        not_altered.append(np.nan)\n",
    "\n",
    "df['Speed Altered'] = altered\n",
    "df['Speed NOT Altered'] = not_altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.DataFrame({x:[0 for race in sorted(list(race_set))] for x in speeding_bool_set}, index=sorted(list(race_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed NOT Altered</th>\n",
       "      <th>Speed Altered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ASIAN</th>\n",
       "      <td>236</td>\n",
       "      <td>3626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLACK</th>\n",
       "      <td>1049</td>\n",
       "      <td>10670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HISPANIC</th>\n",
       "      <td>726</td>\n",
       "      <td>7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NATIVE AMERICAN</th>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>267</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE</th>\n",
       "      <td>1479</td>\n",
       "      <td>24843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Speed NOT Altered  Speed Altered\n",
       "ASIAN                          236           3626\n",
       "BLACK                         1049          10670\n",
       "HISPANIC                       726           7039\n",
       "NATIVE AMERICAN                 10             36\n",
       "OTHER                          267           3179\n",
       "WHITE                         1479          24843"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in contingency_table:\n",
    "    for ind in contingency_table.index:\n",
    "        temp_col = []\n",
    "        for x in zip(df[col], df[f\"{ind} - (D_Race)\"]):\n",
    "            temp_col.append(x[0]==x[1]==1)\n",
    "            \n",
    "        contingency_table[col].loc[ind] = sum(temp_col)\n",
    "\n",
    "        \n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi2 Test\n",
    "\n",
    "Returns (in order):\n",
    "\n",
    "- The test statistic.\n",
    "\n",
    "- The p-value of the test\n",
    "\n",
    "- Degrees of freedom\n",
    "\n",
    "- The expected frequencies, based on the marginal sums of the table.\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test statistic == 231.28605043787022\n",
      "\n",
      " P-Value == 5.66938794054964e-48\n",
      "\n",
      " Degrees of Freedom == 5\n",
      "\n",
      " Expected Frequencies == \n",
      " [[  273.66730625  3588.33269375]\n",
      " [  830.42650489 10888.57349511]\n",
      " [  550.23993604  7214.76006396]\n",
      " [    3.2596313     42.7403687 ]\n",
      " [  244.18890143  3201.81109857]\n",
      " [ 1865.21772009 24456.78227991]]\n",
      "\n",
      " Difference between Actual and Expected Frequencies (Actual - Expected) == \n",
      "\n",
      "                  Speed NOT Altered  Speed Altered\n",
      "ASIAN                   -37.667306      37.667306\n",
      "BLACK                   218.573495    -218.573495\n",
      "HISPANIC                175.760064    -175.760064\n",
      "NATIVE AMERICAN           6.740369      -6.740369\n",
      "OTHER                    22.811099     -22.811099\n",
      "WHITE                  -386.217720     386.217720\n"
     ]
    }
   ],
   "source": [
    "chi2_result = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"\\n Test statistic == {chi2_result[0]}\")\n",
    "print(f\"\\n P-Value == {chi2_result[1]}\")\n",
    "print(f\"\\n Degrees of Freedom == {chi2_result[2]}\")\n",
    "print(f\"\\n Expected Frequencies == \\n {chi2_result[3]}\")\n",
    "\n",
    "print(f\"\\n Difference between Actual and Expected Frequencies (Actual - Expected) == \\n\\n {contingency_table-chi2_result[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Maybe do this in R - Python implementation is not great (scipy doesn't have a regression summary / p-value; statsmodel doesn't make sense)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "regression_df = df[(9<=df['Speed Over Posted Limit']) & (df['Speed Over Posted Limit']<=14)] # all observations where 9 <= speed <= 14 \n",
    "\n",
    "#replace np.nan with 0\n",
    "for x in list(zip(regression_df.isnull().sum(), regression_df.columns)):\n",
    "    if x[0]!=0:\n",
    "        regression_df[x[1]] = regression_df[x[1]].fillna(value=0)\n",
    "    \n",
    "y = regression_df['Speed Altered']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deletions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete non-boolean or non-float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in regression_df.columns:\n",
    "    if regression_df[col].dtype not in ('bool', 'float64'):\n",
    "        del regression_df[col]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Multicollinearity-Causing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete OTHER - (D_Race), exception: 'OTHER - (D_Race)'\n",
      "Failed to delete Headquarters and Special Operations - (D_SubAgency), exception: 'Headquarters and Special Operations - (D_SubAgency)'\n",
      "Failed to delete ESERO - (D_Violation Type), exception: 'ESERO - (D_Violation Type)'\n",
      "Failed to delete Number of writeups, exception: 'Number of writeups'\n"
     ]
    }
   ],
   "source": [
    "multicollinear_cols = ['GEO: OTHER Racial Composition',\n",
    "'OTHER - (D_Race)',\n",
    "'Headquarters and Special Operations - (D_SubAgency)',\n",
    "'ESERO - (D_Violation Type)',\n",
    "'Number of writeups'\n",
    "                      ]\n",
    "\n",
    "for col in multicollinear_cols:\n",
    "    try:\n",
    "        del regression_df[col]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to delete {col}, exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to delete Citation - (D_Violation Type), exception: 'Citation - (D_Violation Type)'\n",
      "failed to delete Warning - (D_Violation Type), exception: 'Warning - (D_Violation Type)'\n",
      "failed to delete Warning - (D_Search Outcome), exception: 'Warning - (D_Search Outcome)'\n",
      "failed to delete Citation - (D_Search Outcome), exception: 'Citation - (D_Search Outcome)'\n"
     ]
    }
   ],
   "source": [
    "misc_del_list = set(\n",
    "['Speed Altered',\n",
    "'Speed NOT Altered',\n",
    "    \n",
    "'Citation - (D_Violation Type)',\n",
    "'Warning - (D_Violation Type)',\n",
    "            \n",
    "'Citation - (D_Search Outcome)',\n",
    "'Warning - (D_Search Outcome)',            \n",
    "])\n",
    "\n",
    "for col in regression_df:\n",
    "    if 'D_Search Outcome' in col:\n",
    "        misc_del_list.add(col)\n",
    "\n",
    "for col in misc_del_list:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        del regression_df[col]\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"failed to delete {col}, exception: {e}\")\n",
    "\n",
    "X = regression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1) #keep this random_state for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Confirm that there's an even proportion of True, False in training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(y_test)-mean(y_train) == 0.00018811136192620204\n",
      "Discrepancy in raw count == 9.9999999999969\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean(y_test)-mean(y_train) == {(abs(np.mean(y_test)-np.mean(y_train)))}\")\n",
    "\n",
    "print(f'Discrepancy in raw count == { (abs(np.mean(y_test)-np.mean(y_train)))*len(regression_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "\n",
    "- Do I need to normalize the data before L1?\n",
    "- Should we add interaction terms for the geo vars?\n",
    "\n",
    "Thoughts:\n",
    "\n",
    "- Results with/without L1 are very different\n",
    "  * All Geo vars have the same coefficients in normal logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With an Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Variable  L1 Coefficient  Normal Logit Coefficient\n",
      "0                                           Intercept       86.068477                   7.09155\n",
      "1                                         Speed Limit        0.193000                   0.46500\n",
      "4                                            Latitude        0.023000                   0.18200\n",
      "29           GEO: ASIAN Average Speed NOT in 9,14 MPH        0.011000                  -0.00600\n",
      "35           GEO: WHITE Average Speed NOT in 9,14 MPH        0.010000                  -0.00600\n",
      "70  INTERACTION: D_ASIAN X GEO: ASIAN Average Spee...        0.004000                   0.00900\n",
      "54  INTERACTION: D_WHITE X GEO: WHITE Average Spee...        0.002000                  -0.04000\n",
      "24           GEO: OTHER Average Speed NOT in 9,14 MPH        0.002000                  -0.00600\n",
      "74  INTERACTION: D_BLACK X GEO: BLACK Average Spee...        0.001000                   0.13700\n",
      "41           GEO: TOTAL Average Speed NOT in 9,14 MPH       -0.000000                  -0.00600\n",
      "43                      GEO: TOTAL Racial Composition        0.000000                   0.20000\n",
      "53  INTERACTION: D_WHITE X GEO: WHITE Percent of C...        0.000000                   0.23900\n",
      "40              GEO: TOTAL Number of Speeding Charges       -0.000000                   0.00000\n",
      "45  GEO: TOTAL Percent of Charges that were NOT CH...        0.000000                  -0.41100\n",
      "46    GEO: NATIVE AMERICAN Number of Speeding Charges       -0.000000                   0.00000\n",
      "49            GEO: NATIVE AMERICAN Racial Composition        0.000000                   0.20000\n",
      "50  GEO: NATIVE AMERICAN Percent of Charges that w...        0.000000                   0.35600\n",
      "39  GEO: WHITE Percent of Charges that were NOT CH...        0.000000                  -0.41100\n",
      "51  GEO: NATIVE AMERICAN Percent of Charges that w...        0.000000                  -0.41100\n",
      "52  INTERACTION: D_WHITE X GEO: WHITE Racial Compo...        0.000000                   0.54100\n",
      "44    GEO: TOTAL Percent of Charges that were CHANGED        0.000000                   0.35600\n",
      "55                      INTERACTION: D_WHITE X D_Male        0.000000                   1.29300\n",
      "73  INTERACTION: D_BLACK X GEO: BLACK Percent of C...        0.000000                   0.05900\n",
      "37                      GEO: WHITE Racial Composition        0.000000                   0.20000\n",
      "57  INTERACTION: D_OTHER X GEO: OTHER Percent of C...        0.000000                   0.02200\n",
      "59                      INTERACTION: D_OTHER X D_Male        0.000000                   0.10900\n",
      "60  INTERACTION: D_NATIVE AMERICAN X GEO: NATIVE A...        0.000000                  -0.00000\n",
      "61  INTERACTION: D_NATIVE AMERICAN X GEO: NATIVE A...        0.000000                  -0.02000\n",
      "63            INTERACTION: D_NATIVE AMERICAN X D_Male        0.000000                  -0.04200\n",
      "64  INTERACTION: D_HISPANIC X GEO: HISPANIC Racial...        0.000000                  -0.09800\n",
      "65  INTERACTION: D_HISPANIC X GEO: HISPANIC Percen...        0.000000                   0.03400\n",
      "66  INTERACTION: D_HISPANIC X GEO: HISPANIC Averag...        0.000000                   0.18000\n",
      "68  INTERACTION: D_ASIAN X GEO: ASIAN Racial Compo...        0.000000                   0.00400\n",
      "69  INTERACTION: D_ASIAN X GEO: ASIAN Percent of C...        0.000000                   0.02200\n",
      "71                      INTERACTION: D_ASIAN X D_Male        0.000000                   0.09000\n",
      "72  INTERACTION: D_BLACK X GEO: BLACK Racial Compo...        0.000000                  -0.24700\n",
      "56  INTERACTION: D_OTHER X GEO: OTHER Racial Compo...        0.000000                  -0.00100\n",
      "38    GEO: WHITE Percent of Charges that were CHANGED        0.000000                   0.35600\n",
      "17           GEO: HISPANIC Number of Speeding Charges        0.000000                   0.00000\n",
      "6                             Contributed To Accident        0.000000                  -0.03800\n",
      "15    GEO: BLACK Percent of Charges that were CHANGED        0.000000                   0.35600\n",
      "11              GEO: BLACK Number of Speeding Charges       -0.000000                   0.00000\n",
      "34              GEO: WHITE Number of Speeding Charges       -0.000000                   0.00000\n",
      "9                                  Driver State != MD        0.000000                   0.00300\n",
      "20                   GEO: HISPANIC Racial Composition        0.000000                   0.20000\n",
      "22  GEO: HISPANIC Percent of Charges that were NOT...        0.000000                  -0.41100\n",
      "23              GEO: OTHER Number of Speeding Charges       -0.000000                   0.00000\n",
      "26    GEO: OTHER Percent of Charges that were CHANGED        0.000000                   0.35600\n",
      "7                                             Car Age        0.000000                   0.00000\n",
      "27  GEO: OTHER Percent of Charges that were NOT CH...        0.000000                  -0.41100\n",
      "28              GEO: ASIAN Number of Speeding Charges       -0.000000                   0.00000\n",
      "31                      GEO: ASIAN Racial Composition        0.000000                   0.20000\n",
      "32    GEO: ASIAN Percent of Charges that were CHANGED        0.000000                   0.35600\n",
      "33  GEO: ASIAN Percent of Charges that were NOT CH...        0.000000                  -0.41100\n",
      "14                      GEO: BLACK Racial Composition        0.000000                   0.20000\n",
      "18        GEO: HISPANIC Average Speed NOT in 9,14 MPH       -0.001000                  -0.00600\n",
      "58  INTERACTION: D_OTHER X GEO: OTHER Average Spee...       -0.006000                   0.02200\n",
      "12           GEO: BLACK Average Speed NOT in 9,14 MPH       -0.011000                  -0.00600\n",
      "21  GEO: HISPANIC Percent of Charges that were CHA...       -0.011000                   0.35600\n",
      "5                                           Longitude       -0.011000                  -0.04800\n",
      "47  GEO: NATIVE AMERICAN Average Speed NOT in 9,14...       -0.015000                  -0.00600\n",
      "30       GEO: ASIAN Number of Citations for Each Stop       -0.015000                  -1.16200\n",
      "36       GEO: WHITE Number of Citations for Each Stop       -0.021000                  -1.16200\n",
      "62  INTERACTION: D_NATIVE AMERICAN X GEO: NATIVE A...       -0.026000                  -0.31500\n",
      "10                                     DL State != MD       -0.032000                  -0.17600\n",
      "48  GEO: NATIVE AMERICAN Number of Citations for E...       -0.039000                  -1.16200\n",
      "19    GEO: HISPANIC Number of Citations for Each Stop       -0.041000                  -1.16200\n",
      "16  GEO: BLACK Percent of Charges that were NOT CH...       -0.053000                  -0.41100\n",
      "67                   INTERACTION: D_HISPANIC X D_Male       -0.064000                  -0.14300\n",
      "75                      INTERACTION: D_BLACK X D_Male       -0.102000                  -0.34100\n",
      "8                                                Male       -0.113000                   0.96500\n",
      "25       GEO: OTHER Number of Citations for Each Stop       -0.118000                  -1.16200\n",
      "13       GEO: BLACK Number of Citations for Each Stop       -0.123000                  -1.16200\n",
      "2                                       Driving Speed       -0.207000                  -0.35400\n",
      "42       GEO: TOTAL Number of Citations for Each Stop       -0.211000                  -1.16200\n",
      "3                             Speed Over Posted Limit       -8.678000                  -0.81900\n"
     ]
    }
   ],
   "source": [
    "l1_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "l1_model.fit(X, y)\n",
    "l1_coefficients = l1_model.coef_.tolist()[0]\n",
    "zipped_l1_coefs = list(zip([['Intercept']+list(regression_df.columns)][0], [l1_model.intercept_.tolist()[0]]+[round(x,3) for x in l1_coefficients]))\n",
    "\n",
    "\n",
    "\n",
    "log_model = LogisticRegression(max_iter=5000) #default max_iter==100\n",
    "log_model.fit(X, y)\n",
    "log_coefficients = log_model.coef_.tolist()[0]\n",
    "zipped_log_coefs = list(zip(['Intercept']+[list(regression_df.columns)][0], [log_model.intercept_.tolist()[0]]+[round(x,3) for x in log_coefficients]))\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({'Variable': [x[0] for x in zipped_l1_coefs],\n",
    "                           'L1 Coefficient': [x[1] for x in zipped_l1_coefs],\n",
    "                           'Normal Logit Coefficient': [x[1] for x in zipped_log_coefs]})\n",
    "\n",
    "results_df = results_df.sort_values(by=['L1 Coefficient'], ascending=False)\n",
    "\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Accuracy\n",
    "\n",
    "**NOTE: THIS WAS NOT SCORING 100% UNTIL ADDING RACExGEO AND RACExMALE INTERACTION TERMS**\n",
    "\n",
    "(it had ~98% accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Stops that appeared to receive leniency == 92.914% \n",
      "\n",
      "\n",
      "l1_model TRAINING accuracy == 100.0%\n",
      "\n",
      "l1_model TESTING accuracy == 100.0% \n",
      " \n",
      "\n",
      "log_model TRAINING accuracy == 94.627%\n",
      "\n",
      "log_model TESTING accuracy == 94.874%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percent of Stops that appeared to receive leniency == { round(100 * np.mean(df[\"Speed Altered\"]), 3) }% \\n\\n')\n",
    "\n",
    "print(f'l1_model TRAINING accuracy == {round(100 * l1_model.score(X_train, y_train), 13)}%\\n')\n",
    "\n",
    "print(f'l1_model TESTING accuracy == {round(100 * l1_model.score(X_test, y_test), 3)}% \\n \\n')\n",
    "\n",
    "\n",
    "print(f'log_model TRAINING accuracy == {round(100 * log_model.score(X_train, y_train), 3)}%\\n')\n",
    "\n",
    "print(f'log_model TESTING accuracy == {round(100 * log_model.score(X_test, y_test), 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Coefficient</th>\n",
       "      <th>Normal Logit Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1 Coefficient</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal Logit Coefficient</th>\n",
       "      <td>0.879278</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          L1 Coefficient  Normal Logit Coefficient\n",
       "L1 Coefficient                  1.000000                  0.879278\n",
       "Normal Logit Coefficient        0.879278                  1.000000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Intercept\n",
    "\n",
    "Can we run this without an intercept? The intercept term is much larger than the next biggest coefficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Variable  L1 Coefficient  Normal Logit Coefficient\n",
      "52  INTERACTION: D_WHITE X GEO: WHITE Percent of C...           4.346                     0.002\n",
      "51  INTERACTION: D_WHITE X GEO: WHITE Racial Compo...           1.752                     0.004\n",
      "54                      INTERACTION: D_WHITE X D_Male           0.387                     0.010\n",
      "20  GEO: HISPANIC Percent of Charges that were CHA...           0.374                     0.003\n",
      "14    GEO: BLACK Percent of Charges that were CHANGED           0.330                     0.003\n",
      "8                                  Driver State != MD           0.272                    -0.000\n",
      "25    GEO: OTHER Percent of Charges that were CHANGED           0.243                     0.003\n",
      "58                      INTERACTION: D_OTHER X D_Male           0.238                     0.001\n",
      "31    GEO: ASIAN Percent of Charges that were CHANGED           0.232                     0.003\n",
      "68  INTERACTION: D_ASIAN X GEO: ASIAN Percent of C...           0.224                     0.000\n",
      "70                      INTERACTION: D_ASIAN X D_Male           0.194                     0.000\n",
      "49  GEO: NATIVE AMERICAN Percent of Charges that w...           0.133                     0.003\n",
      "43    GEO: TOTAL Percent of Charges that were CHANGED           0.122                     0.003\n",
      "61  INTERACTION: D_NATIVE AMERICAN X GEO: NATIVE A...           0.118                    -0.005\n",
      "73  INTERACTION: D_BLACK X GEO: BLACK Average Spee...           0.116                    -0.014\n",
      "0                                         Speed Limit           0.111                     0.253\n",
      "65  INTERACTION: D_HISPANIC X GEO: HISPANIC Averag...           0.090                    -0.010\n",
      "37    GEO: WHITE Percent of Charges that were CHANGED           0.082                     0.003\n",
      "3                                            Latitude           0.068                     0.038\n",
      "57  INTERACTION: D_OTHER X GEO: OTHER Average Spee...           0.046                     0.001\n",
      "69  INTERACTION: D_ASIAN X GEO: ASIAN Average Spee...           0.044                    -0.001\n",
      "1                                       Driving Speed           0.041                    -0.118\n",
      "45    GEO: NATIVE AMERICAN Number of Speeding Charges          -0.000                     0.000\n",
      "39              GEO: TOTAL Number of Speeding Charges           0.000                     0.000\n",
      "63  INTERACTION: D_HISPANIC X GEO: HISPANIC Racial...           0.000                    -0.001\n",
      "42                      GEO: TOTAL Racial Composition           0.000                     0.001\n",
      "13                      GEO: BLACK Racial Composition           0.000                     0.001\n",
      "6                                             Car Age           0.000                     0.000\n",
      "48            GEO: NATIVE AMERICAN Racial Composition           0.000                     0.001\n",
      "19                   GEO: HISPANIC Racial Composition           0.000                     0.001\n",
      "56  INTERACTION: D_OTHER X GEO: OTHER Percent of C...           0.000                     0.000\n",
      "60  INTERACTION: D_NATIVE AMERICAN X GEO: NATIVE A...           0.000                    -0.000\n",
      "59  INTERACTION: D_NATIVE AMERICAN X GEO: NATIVE A...           0.000                    -0.000\n",
      "10              GEO: BLACK Number of Speeding Charges          -0.000                     0.000\n",
      "7                                                Male           0.000                     0.001\n",
      "64  INTERACTION: D_HISPANIC X GEO: HISPANIC Percen...           0.000                    -0.000\n",
      "55  INTERACTION: D_OTHER X GEO: OTHER Racial Compo...           0.000                    -0.000\n",
      "36                      GEO: WHITE Racial Composition           0.000                     0.001\n",
      "27              GEO: ASIAN Number of Speeding Charges           0.000                     0.000\n",
      "72  INTERACTION: D_BLACK X GEO: BLACK Percent of C...           0.000                     0.000\n",
      "22              GEO: OTHER Number of Speeding Charges          -0.000                     0.000\n",
      "33              GEO: WHITE Number of Speeding Charges           0.000                     0.000\n",
      "67  INTERACTION: D_ASIAN X GEO: ASIAN Racial Compo...           0.000                     0.000\n",
      "16           GEO: HISPANIC Number of Speeding Charges           0.000                     0.000\n",
      "30                      GEO: ASIAN Racial Composition           0.000                     0.001\n",
      "29       GEO: ASIAN Number of Citations for Each Stop          -0.000                    -0.012\n",
      "28           GEO: ASIAN Average Speed NOT in 9,14 MPH          -0.010                    -0.030\n",
      "34           GEO: WHITE Average Speed NOT in 9,14 MPH          -0.014                    -0.030\n",
      "23           GEO: OTHER Average Speed NOT in 9,14 MPH          -0.015                    -0.030\n",
      "17        GEO: HISPANIC Average Speed NOT in 9,14 MPH          -0.015                    -0.030\n",
      "11           GEO: BLACK Average Speed NOT in 9,14 MPH          -0.017                    -0.030\n",
      "46  GEO: NATIVE AMERICAN Average Speed NOT in 9,14...          -0.020                    -0.030\n",
      "40           GEO: TOTAL Average Speed NOT in 9,14 MPH          -0.022                    -0.030\n",
      "47  GEO: NATIVE AMERICAN Number of Citations for E...          -0.030                    -0.012\n",
      "4                                           Longitude          -0.034                    -0.070\n",
      "66                   INTERACTION: D_HISPANIC X D_Male          -0.057                    -0.004\n",
      "74                      INTERACTION: D_BLACK X D_Male          -0.126                    -0.006\n",
      "53  INTERACTION: D_WHITE X GEO: WHITE Average Spee...          -0.191                    -0.002\n",
      "32  GEO: ASIAN Percent of Charges that were NOT CH...          -0.250                    -0.005\n",
      "50  GEO: NATIVE AMERICAN Percent of Charges that w...          -0.297                    -0.005\n",
      "35       GEO: WHITE Number of Citations for Each Stop          -0.342                    -0.012\n",
      "9                                      DL State != MD          -0.349                    -0.003\n",
      "12       GEO: BLACK Number of Citations for Each Stop          -0.366                    -0.012\n",
      "41       GEO: TOTAL Number of Citations for Each Stop          -0.385                    -0.012\n",
      "18    GEO: HISPANIC Number of Citations for Each Stop          -0.394                    -0.012\n",
      "24       GEO: OTHER Number of Citations for Each Stop          -0.410                    -0.012\n",
      "21  GEO: HISPANIC Percent of Charges that were NOT...          -0.473                    -0.005\n",
      "62            INTERACTION: D_NATIVE AMERICAN X D_Male          -0.478                    -0.000\n",
      "2                             Speed Over Posted Limit          -0.587                    -0.371\n",
      "38  GEO: WHITE Percent of Charges that were NOT CH...          -1.098                    -0.005\n",
      "26  GEO: OTHER Percent of Charges that were NOT CH...          -1.107                    -0.005\n",
      "5                             Contributed To Accident          -1.560                    -0.000\n",
      "15  GEO: BLACK Percent of Charges that were NOT CH...          -2.344                    -0.005\n",
      "71  INTERACTION: D_BLACK X GEO: BLACK Racial Compo...          -2.382                    -0.002\n",
      "44  GEO: TOTAL Percent of Charges that were NOT CH...          -3.006                    -0.005\n"
     ]
    }
   ],
   "source": [
    "l1_model_no_intercept = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=False)\n",
    "l1_model_no_intercept.fit(X, y)\n",
    "\n",
    "l1_coefficients_no_intercept = l1_model_no_intercept.coef_.tolist()[0]\n",
    "\n",
    "zipped_l1_coefs = list(zip(list(regression_df.columns), [round(x,3) for x in l1_coefficients_no_intercept]))\n",
    "\n",
    "log_model_no_intercept = LogisticRegression(max_iter=5000, fit_intercept=False) #default max_iter==100\n",
    "log_model_no_intercept.fit(X, y)\n",
    "\n",
    "log_coefficients_no_int = log_model_no_intercept.coef_.tolist()[0]\n",
    "\n",
    "zipped_log_coefs_no_intercept = list(zip(list(regression_df.columns), [round(x,3) for x in log_coefficients_no_int]))\n",
    "\n",
    "no_intercept_results_df = pd.DataFrame({'Variable': [x[0] for x in zipped_l1_coefs],\n",
    "                           'L1 Coefficient': [x[1] for x in zipped_l1_coefs],\n",
    "                           'Normal Logit Coefficient': [x[1] for x in zipped_log_coefs_no_intercept]})\n",
    "\n",
    "no_intercept_results_df = no_intercept_results_df.sort_values(by=['L1 Coefficient'], ascending=False)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(no_intercept_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Stops that appeared to receive leniency == 92.914% \n",
      "\n",
      "\n",
      "l1_model_no_intercept TRAINING accuracy == 92.671%\n",
      "\n",
      "l1_model_no_intercept TESTING accuracy == 92.645% \n",
      " \n",
      "\n",
      "log_model_no_intercept TRAINING accuracy == 91.725%\n",
      "\n",
      "log_model_no_intercept TESTING accuracy == 91.789%\n"
     ]
    }
   ],
   "source": [
    "print(f'Percent of Stops that appeared to receive leniency == { round(100 * np.mean(df[\"Speed Altered\"]), 3) }% \\n\\n')\n",
    "\n",
    "print(f'l1_model_no_intercept TRAINING accuracy == {round(100 * l1_model_no_intercept.score(X_train, y_train), 3)}%\\n')\n",
    "\n",
    "print(f'l1_model_no_intercept TESTING accuracy == {round(100 * l1_model_no_intercept.score(X_test, y_test), 3)}% \\n \\n')\n",
    "\n",
    "\n",
    "print(f'log_model_no_intercept TRAINING accuracy == {round(100 * log_model_no_intercept.score(X_train, y_train), 3)}%\\n')\n",
    "\n",
    "print(f'log_model_no_intercept TESTING accuracy == {round(100 * log_model_no_intercept.score(X_test, y_test), 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Table\n",
    "\n",
    "Much lower correlation than with an intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Coefficient</th>\n",
       "      <th>Normal Logit Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1 Coefficient</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal Logit Coefficient</th>\n",
       "      <td>0.087031</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          L1 Coefficient  Normal Logit Coefficient\n",
       "L1 Coefficient                  1.000000                  0.087031\n",
       "Normal Logit Coefficient        0.087031                  1.000000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_intercept_results_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test that each race has the same proclivity to speed (% speeds >14 mph)\n",
    "\n",
    "An implicit assumption is that all races have the same speeding distribution - at least within the ranges of 9-14 MPH. \n",
    "\n",
    "\\\n",
    "However, this is not necessarily the case:\n",
    "\\\n",
    "\n",
    "    As the following cells show, most races seem to follow their own unique speeding distribution (for speeding above 14 MPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def avg_speeds_above_14(race):\n",
    "    temp_list = []\n",
    "    for x in zip(df[f\"{race} - (D_Race)\"], df['Speed Over Posted Limit']):\n",
    "        if x[0]==1 and x[1]>14:\n",
    "            temp_list.append(x[1])\n",
    "            \n",
    "    return np.mean(temp_list)\n",
    "\n",
    "for race in race_set:\n",
    "    print(f\"Average {race} speed over 14 MPH == {avg_speeds_above_14(race)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Simple Z test for different means (speeding above 14 mph), with hypothesized difference between means==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def z_score_above_14(race1, race2):\n",
    "    x1 = np.array([x[0] for x in zip(df['Speed Over Posted Limit'], df['Race']) if x[1]==race1 and 14 < x[0] < 100])\n",
    "    x2 = np.array([x[0] for x in zip(df['Speed Over Posted Limit'], df[\"Race\"]) if x[1]==race2 and 14 < x[0] < 100])\n",
    "\n",
    "    xbar1 = np.mean(x1)\n",
    "    xbar2 = np.mean(x2)\n",
    "    \n",
    "    sig1 = np.std(x1)\n",
    "    sig2 = np.std(x2)\n",
    "    \n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "    \n",
    "    z = (xbar1-xbar2)/np.sqrt((sig1**2)/n1 + (sig2**2)/n2)\n",
    "    \n",
    "    return abs(round(z,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z_tests_above_14_table = pd.DataFrame({race1:[z_score_above_14(race1, race2) for race2 in sorted(list(race_set))] for race1 in sorted(list(race_set))}, index=sorted(list(race_set)))\n",
    "\n",
    "\n",
    "z_tests_above_14_table.style.apply(lambda x: [\"background: red\" if v > 1.96 else \"\" for v in x], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Races probably have different speeding distributions\n",
    "\n",
    "**We should run a test to specifically test similarity of distributions**\n",
    "\n",
    "**Utlimately, we need to investigate whether white/asian/etc. drivers *appear* to receive more leniency because they have more stops actually at 9 mph**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "237.997px",
    "width": "221.449px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
